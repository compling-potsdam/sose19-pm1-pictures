*PM1/2, SoSe 19, Semantics with Pictures, Uni Potsdam, David Schlangen*

# Models we will be looking at

- <https://github.com/yunjey/pytorch-tutorial/tree/master/tutorials/03-advanced/image_captioning>  
Vanilla captioning encoder / decoder model

- <https://github.com/sgrvinod/a-PyTorch-Tutorial-to-Image-Captioning>  
Implements attend, show, and tell

- <https://github.com/sgrvinod/a-PyTorch-Tutorial-to-Object-Detection>  
Implements object detector

- <https://github.com/lichengunc/MAttNet>  
implements referring expression comprehension

- <https://github.com/batra-mlp-lab/visdial-challenge-starter-pytorch>  
  visdial starter kit


Presenters will talk us through the _model_ (architecture, maths) and the _implementation_ (training, inference). Present model at work, so need to have pre-trained weights available and have model ready to be applied (ideally, to data from one of the corpora we have looked at).
